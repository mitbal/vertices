{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kfp.v2 import compiler\n",
    "from kfp.v2.dsl import component, pipeline, Input, Output, Dataset, Model, Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_ID = 'mitochondrion-project-344303'\n",
    "REGION = 'asia-southeast1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUCKET_NAME = 'gs://mitochondrion-bucket-sg'\n",
    "PIPELINE_ROOT = f'{BUCKET_NAME}/pipelines'\n",
    "PIPELINE_NAME = 'marketing-custom-pipeline'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "@component(base_image='google/cloud-sdk:latest',\n",
    "            packages_to_install=['pandas==1.3.4',\n",
    "                                'pandas-gbq==0.17.4',\n",
    "                                'google-cloud-bigquery==2.34.2'\n",
    "            ]\n",
    ")\n",
    "def get_latest_data_from_bq(train_dataset: Output[Dataset],\n",
    "                               test_dataset: Output[Dataset],\n",
    "                               current_date: str = '2022-01-01'):\n",
    "\n",
    "    from datetime import datetime, timedelta\n",
    "    import pandas as pd\n",
    "\n",
    "    start_date = (datetime.strptime(current_date, '%Y-%m-%d') - timedelta(days=7*4)).strftime('%Y-%m-%d')\n",
    "    end_date = (datetime.strptime(current_date, '%Y-%m-%d') - timedelta(days=7)).strftime('%Y-%m-%d')\n",
    "\n",
    "    query = \"\"\"\n",
    "        SELECT\n",
    "        *\n",
    "        FROM\n",
    "        `mitochondrion-project-344303.dataset.marketing`\n",
    "        WHERE\n",
    "        created_date >= '{start_date}'\n",
    "        AND created_date <= '{current_date}'\n",
    "    \"\"\".format(start_date=start_date, current_date=current_date)\n",
    "\n",
    "    df = pd.read_gbq(query, project_id='mitochondrion-project-344303', dialect='standard')\n",
    "\n",
    "    train_df = df[(df['created_date'] >= start_date) & (df['created_date'] <= end_date)]\n",
    "    test_df = df[df['created_date'] == current_date]\n",
    "\n",
    "    train_df.to_csv(train_dataset.path, index=False)\n",
    "    test_df.to_csv(test_dataset.path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "@component(base_image='python:3.9.12',\n",
    "            packages_to_install=['pandas==1.3.4',\n",
    "                                'scikit-learn==1.0.2',\n",
    "            ]\n",
    ")\n",
    "def transform_feature(raw_dataset: Input[Dataset],\n",
    "                        transformed_dataset: Output[Dataset]):\n",
    "\n",
    "    import pandas as pd\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "    df = pd.read_csv(raw_dataset.path)\n",
    "\n",
    "    std = StandardScaler()\n",
    "    std.fit(df[['history']])\n",
    "    transformed_df = pd.DataFrame(std.transform(df[['history']]), columns=['history_std'])\n",
    "\n",
    "    enc = OneHotEncoder(handle_unknown='ignore')\n",
    "    enc.fit(df[['zip_code', 'channel', 'offer']])\n",
    "    transformed_df[enc.get_feature_names_out(['zip_code', 'channel', 'offer'])] = enc.transform(df[['zip_code', 'channel', 'offer']]).toarray()\n",
    "\n",
    "    transformed_df[['used_bogo', 'used_discount', 'is_referral', 'conversion']] = df[['used_bogo', 'used_discount', 'is_referral', 'conversion']]\n",
    "\n",
    "    transformed_df.to_csv(transformed_dataset.path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "@component(base_image='python:3.9.12',\n",
    "            packages_to_install=['pandas==1.3.4',\n",
    "                                'xgboost==1.5.1',\n",
    "                                'scikit-learn==1.0.2',\n",
    "            ]\n",
    ")\n",
    "def train_xgboost_model(dataset: Input[Dataset],\n",
    "                        model_artifact: Output[Model],\n",
    "                        metrics: Output[Metrics]):\n",
    "\n",
    "    import pickle\n",
    "    import pandas as pd\n",
    "    from xgboost.sklearn import XGBClassifier\n",
    "\n",
    "    data = pd.read_csv(dataset.path)\n",
    "    X = data.drop('conversion', axis=1).values\n",
    "    y = data['conversion'].values\n",
    "\n",
    "    xgb = XGBClassifier(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=0)\n",
    "    xgb.fit(X, y)\n",
    "\n",
    "    training_accuracy = xgb.score(X, y)\n",
    "\n",
    "    with open(model_artifact.path, 'wb') as f:\n",
    "        pickle.dump(xgb, f)\n",
    "\n",
    "    metrics.log_metric('training accuracy', training_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "@component(base_image='google/cloud-sdk:latest',\n",
    "            packages_to_install=['pandas==1.3.4',\n",
    "                                'pandas-gbq==0.17.4',\n",
    "                                'google-cloud-bigquery==2.34.2',\n",
    "                                'xgboost==1.5.1',\n",
    "                                'scikit-learn==1.0.2',\n",
    "            ]\n",
    ")\n",
    "def create_batch_prediction(\n",
    "                            dataset: Input[Dataset],\n",
    "                            model_artifact: Input[Model],\n",
    "                            predictions_dataset: Output[Dataset],\n",
    "                            current_date: str = '2022-01-01'\n",
    "):\n",
    "\n",
    "    import pickle\n",
    "    import pandas as pd\n",
    "    from xgboost.sklearn import XGBClassifier\n",
    "\n",
    "    model = pickle.load(open(model_artifact.path, 'rb'))\n",
    "\n",
    "    data = pd.read_csv(dataset.path)\n",
    "    X = data.drop('conversion', axis=1).values\n",
    "    predictions = model.predict(X)\n",
    "\n",
    "    predictions_df = pd.DataFrame({'prediction': predictions})\n",
    "    predictions_df['prediction_date'] = current_date\n",
    "    predictions_df.to_csv(predictions_dataset.path, index=False)\n",
    "\n",
    "    predictions_df.to_gbq('prediction.marketing', 'mitochondrion-project-344303', if_exists='append')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "@pipeline(\n",
    "    pipeline_root=PIPELINE_ROOT,\n",
    "    name=PIPELINE_NAME\n",
    ")\n",
    "def custom_pipeline(\n",
    "    current_date: str = '2022-01-01'\n",
    "):\n",
    "    dataset = get_latest_data_from_bq(current_date=current_date)\n",
    "    transformed_train = transform_feature(dataset.outputs['train_dataset'])\n",
    "    transformed_test = transform_feature(dataset.outputs['test_dataset'])\n",
    "    model = train_xgboost_model(transformed_train.outputs['transformed_dataset'])\n",
    "    create_batch_prediction(transformed_test.outputs['transformed_dataset'], model.outputs['model_artifact'], \n",
    "                            current_date)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mitbal/miniconda3/lib/python3.9/site-packages/kfp/v2/compiler/compiler.py:1263: FutureWarning: APIs imported from the v1 namespace (e.g. kfp.dsl, kfp.components, etc) will not be supported by the v2 compiler since v2.0.0\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "JSON_FILE = 'marketing_custom_pipeline.json'\n",
    "\n",
    "compiler.Compiler().compile(\n",
    "    pipeline_func=custom_pipeline,\n",
    "    package_path=JSON_FILE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:google.cloud.aiplatform.pipeline_jobs:Creating PipelineJob\n",
      "INFO:google.cloud.aiplatform.pipeline_jobs:PipelineJob created. Resource name: projects/832137092875/locations/asia-southeast1/pipelineJobs/marketing-custom-pipeline-20220422011033\n",
      "INFO:google.cloud.aiplatform.pipeline_jobs:To use this PipelineJob in another session:\n",
      "INFO:google.cloud.aiplatform.pipeline_jobs:pipeline_job = aiplatform.PipelineJob.get('projects/832137092875/locations/asia-southeast1/pipelineJobs/marketing-custom-pipeline-20220422011033')\n",
      "INFO:google.cloud.aiplatform.pipeline_jobs:View Pipeline Job:\n",
      "https://console.cloud.google.com/vertex-ai/locations/asia-southeast1/pipelines/runs/marketing-custom-pipeline-20220422011033?project=832137092875\n"
     ]
    }
   ],
   "source": [
    "from google.cloud import aiplatform\n",
    "\n",
    "job = aiplatform.PipelineJob(\n",
    "    display_name = PIPELINE_NAME,\n",
    "    # template_path = JSON_FILE,\n",
    "    template_path = 'gs://mitochondrion-bucket-sg/marketing/marketing_custom_pipeline.json',\n",
    "    enable_caching = True,\n",
    "    project = PROJECT_ID,\n",
    "    location = REGION,\n",
    "    parameter_values = {\n",
    "        'current_date': '2022-02-05'\n",
    "    }\n",
    ")\n",
    "\n",
    "# job.submit()\n",
    "job.submit(service_account='default@mitochondrion-project-344303.iam.gserviceaccount.com')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0c5188a96b217161fb1c005f727af44fe0ad9ac935c05b782336afa836d834ed"
  },
  "kernelspec": {
   "display_name": "Python 3.9.1 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
