{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm.autonotebook import tqdm\n",
    "from vertexai.preview.language_models import TextGenerationModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input parameter start here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "prompt_eval = \"\"\"\n",
    "<INSTRUCTIONS>\n",
    "You are an expert analyst.\n",
    "1. Given a question <QUESTION>, determine if <GENERATED ANSWER> is semantically equivalent to <GROUND TRUTH>\n",
    "2. Given a question <QUESTION>, determine if <GENERATED ANSWER> contains all the key points in the <GROUND TRUTH>\n",
    "3. First, think step-by-step and provide detailed reasoning <REASONING> for your analysis in Step 1 and Step 2. Explain which parts of the <GENERATED ANSWER> is different or similar to the <GROUND TRUTH>\n",
    "4. Then reply with your final answer <FINAL ANSWER> which can only be [Yes, No, Unsure]\n",
    "5. ALWAYS open and close all XML tags for example <FINAL ANSWER></FINAL ANSWER>\n",
    "6. Reasoning must be written in English ONLY.\n",
    "</INSTRUCTIONS>\n",
    "\n",
    "<QUESTION>\n",
    "{0}\n",
    "</QUESTION>\n",
    "<GROUND TRUTH>\n",
    "{1}\n",
    "</GROUND TRUTH>\n",
    "<GENERATED ANSWER>\n",
    "{2}\n",
    "</GENERATED ANSWER>\n",
    "\n",
    "Begin!\n",
    "<REASONING>\n",
    "\"\"\"\n",
    "\n",
    "use_model = 'base'\n",
    "model_name = 'text-bison@latest'\n",
    "\n",
    "FILE_INPUT = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "FILE_OUTPUT = FILE_INPUT.split('.csv')[0]+'-output.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "judge = TextGenerationModel.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(FILE_INPUT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = df.copy(deep=True)\n",
    "result_df['judge_response'] = None\n",
    "result_df['verdict'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in tqdm(df.iterrows()):\n",
    "\n",
    "    input_prompt = prompt_eval.format(row['original_question'], row['ground_truth_answer'], row['generated_answer'])\n",
    "\n",
    "    response = judge.predict(input_prompt, temperature=0, max_output_tokens=1024)\n",
    "\n",
    "    # print(index, response.text)\n",
    "    result_df.loc[index, 'judge_response'] = response.text\n",
    "    result_df.loc[index, 'verdict'] = response.text.split('FINAL ANSWER')[1][1:-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.groupby('verdict').count()['judge_response'].plot(kind='pie', autopct='%1.0f%%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.to_csv(FILE_OUTPUT, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
